---
title: "Red wine quality prediction through machine learning"
subtitle: "HarvardX PH125.9x Data Science: Capstone - Choose your own project"
author: "Priscila Treviño Aguilar"
date: "December, 2020"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align='center')
```

\newpage 

# Acknowledgement

I would like to thank professor Irrizary and the whole HarvardX staff for their superb work on this course, I was very pleased with the content and assignments and I consider that the capstone project did an excellent job of summarizing the skills learned and encouraging practice of the most relevant aspects of the course. As a food scientist and an enthusiast of biological and chemical sciences in general, I’m glad that I was able to incorporate an issue of my choice and that is relevant in the still emerging relation between data science and the food and beverage industry. Completing this capstone project was an exciting and challenging experience in my path to becoming a data scientist. 

&nbsp; 

# 1. Introduction

This capstone project consists in employing the R-programming and statistics skills obtained throughout the course as well as applying the learned machine learning techniques to predict red wine quality. A few machine learning algorithms were fit to the data to predict red wine sensory quality (a score between 1 to 10) in a test set using the inputs of a provided train set.

Nowadays data science and analytics are widely used to support and optimize many different disciplines, food science is not the exception, although the relation with the food and beverage industry is still nascent there are already several ways data science is being applied to improve food and beverage products' development and manufacturing. One such way is the application of data analysis to evaluate and predict the sensory quality of food and beverage products. Sensory analysis is an important food science sub discipline that applies principles of experimental design and statistical analysis to the use of human senses to evaluate the sensory properties of consumer products (Jantis, 1992). This discipline relies on both physicochemical parameters and human expert evaluation to perform its analysis (trained sensory judges and biostatisticians), although those aspects are not completely replaceable, data analysis can aid in better understanding the complex relationship between food physicochemical attributes and sensory quality, providing relatively accurate predictions while also minimizing labor and costs (Cortez et al., 2009). Thus, this application presents an advantage of scientific and economic relevance.

The dataset used in this project is related to a red variant of the Portuguese "Vinho Verde" wine. It consists of 11 input variables (wine physicochemical parameters) and one output variable (wine quality based on sensory analysis data), it's publicly available at UCI machine learning repository and Kaggle and it was obtained from a research paper by Cortez et al., (2009) in which data mining was used to perform wine quality assessment.

The analysis approach in this project was more simple. Exploratory data analysis was performed and, although the data set was already clean for its analysis, highly correlated variables were eliminated to promote better model fitting. Since this data set can be seen as a regression or a classification task, both approaches were taken in this project. Two regression models were fit to the data (Regression tree and Random Rorest regression), as well as two classification models (Naive Bayes and Random Forest classification). The regression models were evaluated by computing their root mean squared error (RMSE). For the classification models, the integer output variable was converted into a dichotomous categorical variable by setting a cutoff to determine if a wine was considered moderate or high quality based on hedonic scales commonly used in sensory analysis tests and they were evaluated through their accuracy and as well as their ROC curve and AUC calculation.


```{r required packages installation, echo=FALSE}

if(!require(caret))install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(dyplr))install.packages("dyplr", repos = "http://cran.us.r-project.org")
if(!require(ggplot2))install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(rpart))install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(rpart.plot))install.packages("rpart.plot", repos = "http://cran.us.r-project.org")
if(!require(randomForest))install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(Rborist))install.packages("Rborist", repos = "http://cran.us.r-project.org")
if(!require(klaR))install.packages("klaR", repos = "http://cran.us.r-project.org")
if(!require(ggsci))install.packages("ggsci", repos = "http://cran.us.r-project.org")
if(!require(mlbench))install.packages("mlbench", repos = "http://cran.us.r-project.org")
if(!require(gapminder))install.packages("gapminder", repos = "http://cran.us.r-project.org")
if(!require(forcats))install.packages("forcats", repos = "http://cran.us.r-project.org")
if(!require(pROC))install.packages("forcats", repos = "http://cran.us.r-project.org")
if(!require(ggthemes))install.packages("ggthemes", repos = "http://cran.us.r-project.org")
if(!require(corrplot))install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(e1071))install.packages("e1071", repos = "http://cran.us.r-project.org")
if(!require(MLeval))install.packages("MLeval", repos = "http://cran.us.r-project.org")
if(!require(knitr))install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(gridExtra))install.packages("gridExtra", repos = "http://cran.us.r-project.org")
if(!require(params))install.packages("params", repos = "http://cran.us.r-project.org")
if(!require(rmarkdown))install.packages("rmarkdown", repos = "http://cran.us.r-project.org")
if(!require(tinytex))install.packages("tinytex", repos = "http://cran.us.r-project.org")
```

```{r required libraries loading, echo=FALSE}

library(caret)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(randomForest)
library(Rborist)
library(klaR)
library(ggsci)
library(mlbench)
library(gapminder)
library(forcats)
library(pROC)
library(ggthemes)
library(corrplot)
library(e1071)
library(MLeval)
library(knitr)
library(gridExtra)
library(params)
library(rmarkdown)
library(tinytex)
```

```{r data loading, echo=FALSE}

wine <- read.csv(url("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"), 
                 header = TRUE, 
                 sep = ";")
```

\newpage

# 2. Methods

## Exploratory data analysis

The structure of the data set showed that it contained 1599 distinct observations, 11 numeric input variables and one integer output variable. 

```{r structure}
str(wine, width=80, strict.width="cut")
```

A look at summary and class of the variables gave a more clear idea of their properties and values. 

```{r summary}
summary(wine)
```

\newpage

```{r class}
sapply(wine, class)
```

The data set did not contain any NA values.

```{r no NAs}
any(is.na(wine))
```

Technical particularities of the data set's variables were studied further to have a better understanding of their possible influence on the final product.

&nbsp;  

Table 1: Variable description

Column/Variable           Description
-----------------------   -------------------------------------------------------------------------------------------
fixed.acidity             Nonvolatile acids (do not evaporate readily)
volatile.acidity          Acetic acid in wine (high levels cause unpleasant flavor)
citric.acid               Adds 'freshness' and flavor to wines, present in small quantities
residual.sugar            Remaining sugar after fermentation stops
chlorides                 The amount of salt in the wine
free.sulfur.dioxide       Prevents microbial growth and the oxidation of wine
total.sulfur.dioxide      Free and bound forms of sulfur dioxide, usually present in low concentrations
density                   Dependent on the alcohol percentage and sugar content
pH                        Describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic)
sulphates                 A wine additive which acts as an antimicrobial and antioxidant
alcohol                   Alcohol percentage
quality                   Output variable (based on sensory analysis data, score between 0 and 10)
-----------------------  --------------------------------------------------------------------------------------------

\newpage

By visualizing the distribution of the quality data below it was observed that the majority of the wines in the data set are rated between 5 to 6 and there are few wines with very low or very high rating. The distribution is slightly left skewed and the tall peak indicates that the data is close to the mean (low standard deviation). 

```{r quality rating histogram, echo=FALSE, fig.height = 4, fig.width = 6}

wine %>%  # quality rating distribution
  ggplot(aes(quality)) + 
  geom_histogram(binwidth = 0.25, color = "#B22222", fill = "#8B0000") + 
  theme_economist() + 
  xlab("Quality") +
  ylab("Wine count") + 
  ggtitle("Wine quality rating distribution") + 
  theme(plot.title = element_text(hjust = 0.5))
```

This was confirmed by computing the quality mean, median and standard deviation.

```{r measures of central tendency computation}

mean(wine$quality)
median(wine$quality)
sd(wine$quality)
```


One of the most important attributes that influence the quality of wines is the aroma. Wine aroma is extremely complex, determined by volatile compounds present in very low concentrations that have a synergic effect on the final quality. These volatile compounds generally include alcohols, esters, aldehydes, acids, phenols and sulfur compounds (Sanchez-Palomo et al., 2018).
Upon consulting scientific literature on wine sensory properties and its general flavor profile, it was found that among the physicochemical parameters available in this project's data set, volatile acidity and alcohol content might be the ones with the most substantial effect on wine sensory quality. To attempt to better understand what makes a high quality wine, these variables were studied further through literary research and visualization. 

The absolute amount of acids in wine may affect other parameters, such as pH, sugar and ethanol concentrations. Maintaining a low pH is also crucial to the color stability of red wines (which is also a relevant aspect of the sensory experience). Volatile acidity itself refers to acetic acid which is essential for conveying a vinegary and pungent aroma (sourness) (Villamor, 2012) (Sanchez-Palomo et al., 2018).


```{r volatile acidity plots, echo=FALSE, fig.height = 7, fig.width = 5}

va_wineplot <- wine %>%   # volatile acidity histogram
  ggplot(aes(volatile.acidity)) + 
  geom_histogram(binwidth = 0.25, color = "#B22222", fill = "#8B0000") + 
  theme_economist() + 
  xlab("Volatile acidity") +
  ylab("Wine count") + 
  ggtitle("Wine volatile acidity distribution") + 
  theme(plot.title = element_text(hjust = 0.5))

vaq_wineplot <- wine %>%  # quality per volatile acidity plot 
  ggplot(aes(x = quality, y = volatile.acidity, color = quality)) + 
  geom_point(color = "#8B0000") + 
  theme_economist() +  
  xlab("Quality") +
  ylab("Volatile acidity") + 
  ggtitle("Quality distribution per volatile acidity") + 
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(va_wineplot, vaq_wineplot, nrow = 2)  # grid arrange
```

The plots above showed the distribution of volatile acidity among wines and seemed to indicate that higher quality wines tend to contain smaller values of volatile acidity. 

\newpage

Alcohol content can directly affect the aroma perception in wine, for example, at low ethanol concentration (10.0 to 12.0%) it has been described as fruity while at higher ethanol concentrations it has been defined as herbaceous. Alcohol content has also been shown to increase the perceived viscosity in wine, which in turn has an effect on the intensity of how volatile compounds in wine are perceived (Villamor, 2012) (Yildirim et al., 2005). 


```{r alcohol content plots, echo=FALSE, fig.height = 7, fig.width = 5}

ac_wineplot <- wine %>%  # alcohol content histogram
  ggplot(aes(alcohol)) + 
  geom_histogram(binwidth = 0.25, color = "#B22222", fill = "#8B0000") +
  theme_economist() + 
  xlab("Alcohol content") +
  ylab("Wine count") + 
  ggtitle("Wine alcohol content distribution") + 
  theme(plot.title = element_text(hjust = 0.5))

acq_wineplot <- wine %>%  # quality per alcohol content plot 
  ggplot(aes(x = quality, y = alcohol, color = quality)) + 
  geom_point(color = "#8B0000") + 
  theme_economist() +  
  xlab("Quality") +
  ylab("Alcohol content") + 
  ggtitle("Quality distribution per alcohol content") + 
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(ac_wineplot, acq_wineplot, nrow = 2)  # grid arrange
```

In the plots above it was observed that most wines belong to the range of low ethanol concentration. The quality distribution indicates that high quality wines with ratings between 7 to 8 tend to have higher alcohol content, however the relationship between alcohol content and quality was not entirely clear. 

\newpage

The integer output variable, quality, was transformed into a dichotomous categorical variable to make a distribution plot of wines considered to be of moderate or high quality (as well as for subsequent model fitting). 
The cutoff value decision was taken based on hedonic scales commonly used in sensory analysis. The wine rating sentiment and description were extrapolated to this project's data set quality scale, so it was considered that a rating of 5 or lower represented that the trained sensory judge neither liked nor disliked the wine and thus the wine’s quality was below average to average (moderate quality). Whereas a rating of 6 or higher meant that the wine’s quality was good to extraordinary since it represented that the judge liked it (high quality) (Marks, 2019). 

&nbsp; 

Table 2: Comparison of the hedonic scale and the trained sensory judge sentiment description table for wine quality

Rating    9-point hedonic scale         Rating     Sentiment
-------   -------------------------     --------   ------------------------------------------
9         Like extremely                96-100     Extraordinary
8         Like very much                90-95      Outstanding
7         Like moderately               80-89      Very good to barely above average
6         Like slightly                            
5         Neither like nor dislike      70-79      Average, soundly made, little distinction
4         Dislike slightly                         
3         Dislike moderately            60-69      Below average, notable deficiencies
2         Dislike very much                        
1         Dislike extremely             50-59      Unacceptable
-------   -------------------------     --------   ------------------------------------------

The strip plot below shows the distribution of moderate and high quality wines. 

```{r wine category plot, echo=FALSE, fig.height = 4, fig.width = 6}

category_wineplot <- wine %>%
                mutate(category = cut(quality,
                breaks = c(-Inf,5,Inf),             # the integer output variable was transformed...
                labels = c("Moderate", "High")))   # ...into a dichotomous categorical variable
                
ggplot(category_wineplot,  # strip plot
  aes(x = category, y = quality, color = category)) +
  geom_jitter() +
  theme_economist() +
  scale_color_uchicago() +
  xlab("Category") +
  ylab("Quality rating") + 
  ggtitle("Wine category distribution") + 
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5))
```

\newpage

The amount of wines in each category was computed below.

```{r amount of wines in each category}

sum(category_wineplot$category == "Moderate") 
sum(category_wineplot$category == "High")
```

Finally, the multivariate plot below seemed to confirm that, roughly, high quality wines tended to have low concentrations of volatile acidity and higher alcohol content.

```{r multivariate plot, echo=FALSE, fig.height = 4, fig.width = 6}

ggplot(category_wineplot, aes(x = alcohol, y = volatile.acidity, color = category)) +  # multivariate plot 
  geom_point() +                                       
  theme_economist() +
  scale_color_uchicago() + 
  ggtitle("Category by volatile acidity and alcohol content") +
  xlab("Alcohol content") + 
  ylab("Volatile acidity") + 
  theme(legend.position = "right", 
        legend.text = element_text(size=10),
        title = element_text(size=8),
        plot.title = element_text(hjust = 0.5))
```

However, the models employed afterwards on this project helped elucidate whether these variables played a particularly important role in wine quality prediction and also whether other variables were significant. 

\newpage

## Data cleaning

To promote better model fitting, variables with a moderate to high correlation were eliminated. This is due to the fact that highly correlated variables may impart the same information to the model, adding noise instead of incremental information. First, a correlation matrix was created (correlation plot below), then a cutoff was set to find variables that were relatively highly correlated. Variable correlation was observed in the plot below. 

```{r correlation matrix and plot, echo=FALSE, fig.height = 3, fig.width = 5}

correlationMatrix <- cor(wine[,1:11])

corrplot(correlationMatrix,  # correlation plot     
          order = "hclust", addrect = 7, 
          col = c("darkgray", "darkred"), 
          bg = "azure2") 
```

The variables eliminated were fixed acidity, citric acid and total sulfur dioxide (shown below).

```{r correlated variables removal}

correlated <- findCorrelation(correlationMatrix, cutoff = 0.5)  # the cutoff was set
print(correlated)
correlationMatrix[,c(1,3,7)]  # identified highly correlated attributes by their index                                             
wine_clean <- select(wine, -c(1,3,7))  # correlated variables removal
```

\newpage

## Regression models fitting

The evaluation metric chosen was the root mean squared error (RMSE). A commonly used metric (loss function) for regression models that indicates the absolute fit of the model to the data, that is how close the observed data points are to the model’s predicted values. RMSE is a negatively-oriented score, which means that lower values are better, and it expresses average model prediction error in units of the variable of interest. The following code chunk shows a function to compute the RMSE of the models. 

```{r RMSE function}

RMSE <- function(actual, predicted){
  sqrt(mean((actual - predicted)^2))
}
```

Data partition to obtain train and test sets for the regression models was performed.

```{r data partition for regression}

set.seed(6, sample.kind="Rounding")
test_index <- createDataPartition(y = wine_clean$quality, times = 1, p = 0.2,  
                                  list = FALSE)  # data partition

train_reg <- wine_clean[-test_index,] # train and test sets
test_reg <- wine_clean[test_index,]
```

### Regression tree

Regression/classification tree is a supervised learning algorithm built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches. The algorithm allocates the data into two first partitions and then selects the splits that minimize the sum of the squared deviations from the mean in the two separate partitions. This splitting rule is then applied to each of the new branches until each node reaches a specified minimum node size and becomes a terminal node. It can be used for both classification and regression problems. In this case it was implemented with the *rpart* function. 

```{r regression tree model}

reg_tree <- rpart(quality ~ .,       # regression tree fit 
                  data = train_reg, 
                  method = "anova")

reg_tree$cptable  # results
```

\newpage

```{r cp plot, echo=FALSE}

plotcp(reg_tree)  
```

&nbsp; 

The plot above shows that the model automatically applied a range of cost complexity and performed cross validation.
However, more specific cross validation was needed to ensure the use of optimal parameters (the cross validation process for this model was purposely made extensive to demonstrate the skills obtained in the course, the following techniques applied to the rest of the models were more concise), so further model improvement was achieved with hyper parameter tuning through a grid search (shown in the code chunk below).

```{r cross validation tree}

tuning_grid <- expand.grid(minsplit = seq(3, 20, 1), maxdepth = seq(5, 15, 1))  
nrow(tuning_grid)  # number of combinations in tuning grid


model_comb <- list()    
for (i in 1:nrow(tuning_grid)) {  # for loop to automate model training combinations 
  minsplit <- tuning_grid$minsplit[i]
  maxdepth <- tuning_grid$maxdepth[i]
  
  model_comb[[i]] <- rpart(quality ~ .,
    train_reg,
    method  = "anova",
    control = list(minsplit = minsplit, maxdepth = maxdepth)
  )
}


opt_cp <- function(x) {            # function to obtain the optimal cp
  min    <- which.min(x$cptable[, "xerror"])
  cp <- x$cptable[min, "CP"] 
}


min_error <- function(x) {         # function to obtain the minimum error
  min    <- which.min(x$cptable[, "xerror"])
  xerror <- x$cptable[min, "xerror"] 
}



tuning <- tuning_grid %>%   # grid search results
       mutate(cp = purrr::map_dbl(model_comb, opt_cp), 
       error = purrr::map_dbl(model_comb, min_error)) %>%
       arrange(error) %>%
       top_n(-5, wt = error)
```

Optimal parameters were computed.

```{r optimal parameters tree}

tuning[1,] # optimal parameters
tuning[1,3] # optimal cp
```

Trees are usually pruned to counter overfitting. Overfitting happens when a model memorizes its training data so well that it is learning noise on top of the signal. Machine learning is a problem of trade-offs, the classic issue is overfitting versus underfitting. In this case, pruning should reduce the size of the tree without reducing predictive accuracy. The tuning parameter chosen to optimize the model’s performance was the cost complexity (trade-off with the value that is delivered by complexity), and the optimal value obtained on the previous cross validation was used. 

```{r tree pruning}

pruned_tree <- prune(reg_tree, cp = 0.01)
```

\newpage

Variable importance was plotted as shown below (top five most important variables), and it was confirmed that alcohol content and volatile acidity have a significant effect on predicting wine quality, along with sulphates, density and chlorides. 

```{r variable importance plot tree, echo=FALSE, fig.height = 5, fig.width = 6}

Importance <- as.numeric(pruned_tree$variable.importance[1:5])
Variable <- c("Alcohol", "Sulphates", "Volatile acidity", "Density", "Chlorides")
treevar_plot <- data.frame(Variable, sort(Importance)) # data frame to create plot

treevar_plot %>% ggplot(aes(x = reorder(Variable, Importance),   # variable importance plot
                       y = Importance, fill = Variable)) + 
                       geom_bar(stat = "identity", width = .6) + 
                       scale_fill_lancet() + 
                       coord_flip() + 
                       theme_economist() + 
                       ggtitle("Variable importance in wine quality") + 
                       theme(axis.title.y = element_blank(),
                       plot.title = element_text(size=12, hjust = 0.5),
                       legend.title = element_blank(),
                       legend.position = "none")
```

\newpage


A tree plot was generated below from the final pruned tree using the *rpart.plot* package.

```{r tree plot, echo=FALSE, fig.height = 3, fig.width = 5}

rpart.plot(pruned_tree, type = 3, digits = 3, fallen.leaves = TRUE)  
```

The pruned tree plot above was adjusted and simplified with the *prp* function.

```{r adjusted tree plot, echo=FALSE, fig.height = 4, fig.width = 6}

prp(pruned_tree, 
    fallen.leaves = TRUE, 
    branch = .5,
    faclen = 3,
    shadow.col = "darkcyan", 
    branch.lty = 3, 
    split.cex = 1, 
    split.prefix = "is ", 
    split.suffix = "?", 
    split.box.col = "azure2", 
    split.border.col = "darkcyan",
    split.round = .5)
```

Regression tree's RMSE was computed and saved.

```{r regression tree RMSE}

regtree_pred <- predict(pruned_tree, test_reg) # model evaluation through RMSE
regtree_rmse <- RMSE(test_reg$quality, regtree_pred) 
print(regtree_rmse)  
```


### Random Forest regression

To mitigate the decision tree model’s possible overfitting and attempt to improve the RMSE the random forest algorithm was used. Random forest is a supervised learning algorithm that builds an ensemble of regression or classification trees, usually trained with the bagging method. The general idea of the bagging method is that a combination of learning models increases the overall result, in this case, the multiple trees obtained are merged to get a more accurate and stable prediction. It can be used for both classification and regression problems. First the *randomForest* package was used.

```{r random forest regression model}

reg_forest <- randomForest(quality ~ .,  # random forest regression fit 
                       data = train_reg, 
                       type = "regression", 
                       proximity = TRUE)
```


Variable importance was plotted below once more, this time using an automatic function from the *randomForest* package.

```{r variable importance plot forest regression, echo=FALSE, fig.height = 4, fig.width = 5}

varImpPlot(reg_forest)
```

\newpage

The train function from the *caret* package was used afterwards for this regression model along with the *Rborist* package and method to perform cross validation. In this case the relevant tuning parameters were *predFixed* which is the number of trial predictors for a split (mtry) and *minNode* which is the minimum number of distinct row references to split a node.

```{r cross validation forest regression}

regforest_cv <- train(quality ~ .,  # cross validation
      method = "Rborist",
      tuneGrid = data.frame(predFixed = 3, minNode = c(3, 50)),
      data = train_reg)
```

Random forest regression's RMSE was computed and saved.

```{r forest regression RMSE}

regforest_pred <- predict(regforest_cv, test_reg) # model evaluation through RMSE
rf_rmse <- RMSE(test_reg$quality, regforest_pred)
print(rf_rmse)
```


## Classification models fitting

As per the explanation discussed before, the cutoff to transform the data set's integer output variable into a categorical variable was set.

```{r integer to categorical variable}

# Dichotomization of the integer output variable into moderate quality and high quality

category <- cut(wine_clean$quality,  
           breaks = as.character(c(-Inf, 5, Inf)),  # setting the cutoff
           labels = c("Moderate", "High"), 
           include.lowest = TRUE)
```

The new data set was created and data partition to obtain train and test sets for the classification models was performed.

```{r data partition for classification}

class_set <- wine_clean %>% mutate(category = category) %>% select(-9) 
head(class_set)  # the new category column was added

set.seed(6, sample.kind="Rounding")
test_index <- createDataPartition(y = class_set$category, times = 1, p = 0.2,  
                               list = FALSE)  # data partition

train_class <- class_set[-test_index,]  # train and test sets
test_class <- class_set[test_index,]
```


The *caret* package train function was also used for the classification models, and the appropriate model control arguments were provided to perform repeated cross validation. The ROC metric was used to create a curve plot for these models. 

```{r train control for classification}

# Computations control for cross validation with the train function 
models_control <- trainControl(method = "repeatedcv",
                               number = 10, 
                               repeats = 3, 
                               classProbs = TRUE, 
                               savePredictions = TRUE,
                               summaryFunction = twoClassSummary)
```

### Naive Bayes classification 

Naive Bayes is a classification algorithm for binary (two-class) and multi-class classification problems which simplifies the probability calculation for each hypothesis to make it more tractable. Rather than attempting to calculate the values of each attribute value, they are assumed to be conditionally independent. This is a very strong assumption that is most unlikely in real data. Nevertheless, the approach performs surprisingly well on data where this assumption does not hold. First, it converts the data set into a frequency table, then it creates a likelihood table by finding specific probabilities, and finally it uses the Naive Bayes equation to calculate posterior probability for each class (in this case moderate or high quality wine). The class with the highest posterior probability is the outcome of prediction.


```{r naive bayes model}

bayes_class <- train(category~.,  # Naive Bayes fit 
              data = train_class,
              method = "nb",
              metric = "ROC", 
              trControl = models_control) # cross validation

bayes_class$results  # results
bayes_class$bestTune
```

\newpage

Variable importance was plotted and it was observed to be very similar to that of the regression models.

```{r variable importante plot naive bayes, echo=FALSE, fig.height = 5, fig.width = 6}

temp_nb <- varImp(bayes_class)
plot(temp_nb)  # variable importance plot
```

The evaluation metric of choice for the classification models was the accuracy. Model accuracy in terms of classification models can be defined as the ratio of correctly classified samples to the total number of samples.
Naive Bayes' confusion matrix and accuracy results were computed and saved.

```{r accuracy naive bayes}

nb_accuracy <- confusionMatrix(predict(bayes_class, test_class), 
                               test_class$category)$overall["Accuracy"]
print(nb_accuracy)   # model evaluation through accuracy
```

\newpage

### Random forest classification
This time the random forest algorithm was used for classification and the relevant parameter for cross validation was mtry, which refers to the number of variables available for splitting at each tree node. 

```{r random forest classification model}

forest_class <- train(category~ .,  # random forest classification fit
                      data = train_class,
                      method = "rf", 
                      metric = "ROC",
                      trControl = models_control,
                      tunegrid = expand.grid(mtry = c(1:15))) # cross validation
```

A further look at this model was taken by plotting its variable importance below.

```{r variable importance forest classification, echo=FALSE, fig.height = 5, fig.width = 6}

temp_rf <- varImp(forest_class)
plot(temp_rf)  # variable importance plot
```

```{r single tree plot forest classification, echo=FALSE, fig.height = 4, fig.width = 6}

class_treeplot <- rpart(category~ .,  # plot of a single classification tree
                   data = train_class, 
                   method = "class")
prp(class_treeplot,                      
    fallen.leaves = TRUE, 
    branch = .5,
    faclen = 3,
    shadow.col = "darkcyan", 
    branch.lty = 3, 
    split.cex = 1, 
    split.prefix = "is ", 
    split.suffix = "?", 
    split.box.col = "azure2", 
    split.border.col = "darkcyan",
    split.round = .5)
```

A single classification tree was plotted above.

Random forest classification's confusion matrix and accuracy were computed and saved.

```{r accuracy forest classification}

rf_accuracy <- confusionMatrix(predict(forest_class, test_class),  
                test_class$category)$overall["Accuracy"]
print(rf_accuracy)  # model evaluation through accuracy
```

\newpage

An ROC curve of the two classification models was plotted below. ROC curves demonstrate the tradeoff between sensitivity and specificity, they also allow to study model’s accuracy and compare multiple models. This approach could be useful and relevant in the context of the wine industry and wine quality determination where there is a great benefit from a true positive and not too high cost of a false positive. In this case, by comparing the two models it was observed the random forest model presented a higher AUC value, which indicates how much the model is capable of distinguishing between classes.

&nbsp; 

```{r ROC curves, echo=FALSE, fig.height = 4, fig.width = 6}

models <- list(bayes_class, forest_class)
plot_roc <- evalm(models,   # ROC curves plot
                  plots='r',
                  gnames = c("Naive Bayes", "Random Forest"), 
                  title = "Classification models ROC curves")
```

\newpage

# 3. Results 

```{r results, echo=FALSE}

reg_results <- data.frame(Model = c("Regression tree", "Random Forest Regression"), 
                 RMSE = c(regtree_rmse, rf_rmse))
kable(reg_results, caption = "Results of regression models") # regression results table

class_results <- data.frame(Model = c("Naive Bayes", "Random Forest Classification"), 
                            Accuracy = c(nb_accuracy, rf_accuracy))
kable(class_results, caption = "Results of classification models") # classification results table
```

The models fitted to the data set on this project successfully predicted wine quality ratings in the test set. As expected the random forest regression was more effective than the regression tree algorithm, presenting a lower RMSE value. This might be explained by the fact that random forests tend to perform better because their trees are diverse, each one is learned on a random sample, and at each node, a random set of features are considered for splitting, which results in a smoother decision boundary.
The random forest classification also slightly outperformed the Naive Bayes model presenting a higher accuracy, this might be due to the fact that the Naive Bayes algorithm performs better in cases where the input variables are categorical as opposed to numerical. This is because for numerical variables a normal distribution is assumed, which is a strong assumption. The variable importance for prediction was practically the same in all models, alcohol content was the most significant predictor followed by volatile acidity and sulphates. 


(Lantz and Brett, 2013) (Schumacker, 2014) (Irrizary, 2019)


# 4. Conclusion

Red wine quality was successfully predicted with both regression and categorical approaches and the evaluation metrics utilized are acceptable for this project's specific task, however, more sophisticated evaluation metrics could also be used to determine the model's prediction effectiveness. Further model improvement and also fitting other models should not be discarded, as machine learning is the art of trial and error of finding the best features. 
In this project a real-world application of data science and machine learning was presented. Data driven sensory quality prediction is relevant not only in the wine industry but also in the food science domain in general, plus these techniques are also being applied to resolve other matters, such as food shelf life prediction, food market trends analysis, processes automatization and standardization, among others. 
As previously stated, data analysis is not meant to replace the human labor element of this discipline but to complement it to promote understanding of the link between physicochemical characterization and products’ quality while also minimizing subjective error. There is a promising outlook for this data science application as it is increasingly being implemented and improved with diverse powerful approaches such as data mining, neural networks and support vector machines. 

\newpage

# References 

Jantis J.E. 1992. The Role of Sensory Analysis in Quality Control. ASTM publications, Philadelphia. 

Cortez, Paulo & Teixeira, Juliana & Cerdeira, António & Almeida, Fernando & Matos, Telmo & Reis, José. (2009). Using Data Mining for Wine Quality Assessment. 66-79. 

Marks D. 2019. A critique of wine ratings. American association of wine economists. No. 239 

Sanchez-Palomo E., Izquierdo Cañas P.M., Delgado J.A., Gonzalez Viñas, M.A. 2018. Sensory Characterization of Wines Obtained by Blending Cencibel Grapes and Minority Grape Varieties Cultivated in La Mancha Region. Hindawi Journal of Food Quality. Wiley.

Villamor R.R. 2012. The impact of wine components on the chemical and sensory properties of wines. School of food science. Washington state university.

Yildirim H, Yucel U, Elmaci Y, Ova G and Altug T. 2005. Interpretation of organic wine's flavour profile by multivariate statistical analysis. Department of food engineering, Ege University, Turkey. 

Lantz B. 2013. Machine Learning with R. Packt Publishing. 

Schumacker R.E. 2014. Learning statistics using R. Sage. 

Irizarry R.A. 2019. Introduction to data science. CRC Press.

\newpage

# Appendix 

```{r environment}
# Environment
print("Operating System:")
version
```

